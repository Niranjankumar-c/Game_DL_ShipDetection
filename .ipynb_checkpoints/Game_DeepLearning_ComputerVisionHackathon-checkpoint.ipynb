{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A8i7TigzEMMr"
   },
   "source": [
    "# Analytics Vidhya - Game of Deep Learning || Computer Vision Hackathon\n",
    " - Competition Link: https://datahack.analyticsvidhya.com/contest/game-of-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cjzye_IpEMMv"
   },
   "source": [
    "# Problem Statement\n",
    "Ship or vessel detection has a wide range of applications, in the areas of maritime safety, fisheries management, marine pollution, defence and maritime security, protection from piracy, illegal migration, etc.\n",
    "\n",
    "Keeping this in mind, a Governmental Maritime and Coastguard Agency is planning to deploy a computer vision based automated system to identify ship type only from the images taken by the survey boats. You have been hired as a consultant to build an efficient model for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pvw6ZKWJEMMz"
   },
   "source": [
    "There are 5 classes of ships to be detected which are as follows:\n",
    "\n",
    "* Cargo\n",
    "* Military\n",
    "* Carrier\n",
    "* Cruise\n",
    "* Tankers\n",
    "\n",
    "\n",
    "![](https://datahack.analyticsvidhya.com/media/__sized__/contest_cover/god_2-thumbnail-1200x1200-90.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach\n",
    " - Created a Custom Pytorch Data loader function\n",
    " - Used Pytorch Pretrained Models\n",
    " - Used Resnet50, Resnet152 and Resnet101\n",
    " - Final Submission is result of votings based on 3 submission files created from 3 different models:\n",
    "     - Image size 224x224\n",
    "     - Data Augmenation\n",
    "     - Stratified Sampling split for training and validation data because of data imbalance\n",
    "     - Pre-trained network(resnet50, Resnet152 and Resnet101) - Unfreezed All Layers\n",
    "     - Saved the best model with good accuracy and used that to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Aofk43HEMM2"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oLlv8HmbEMM7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os.path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ulrqIIyPEMNF"
   },
   "outputs": [],
   "source": [
    "#define the transformations\n",
    "transform_ship = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfuUqgjeEMNQ"
   },
   "outputs": [],
   "source": [
    "SEED = 200\n",
    "base_dir = '../input/'\n",
    "\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYHTONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0fvHoAAWEMNa"
   },
   "source": [
    "# Custom class for loading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGUPI6R3EMNd"
   },
   "outputs": [],
   "source": [
    "#read the train csv\n",
    "\n",
    "train_data = pd.read_csv(base_dir+'/train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "nPSBBr-lEMNo",
    "outputId": "ca40d9c8-5fcd-4881-cd08-c8749d9e47d7"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmI9zJ3vmzPb"
   },
   "outputs": [],
   "source": [
    "### map imge names to labels\n",
    "map_img_class_dict = {k:v for k, v in zip(train_data.image, train_data.category)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "RXva-0L5EMOO",
    "outputId": "acd6563f-e8cd-4d18-daa0-ebeebf0a1e09"
   },
   "outputs": [],
   "source": [
    "#read the test csv\n",
    "\n",
    "test_data = pd.read_csv(base_dir+'/test_ApKoW4T.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJRNzk2vnIS1"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class ShipDataLoader(torch.utils.data.DataLoader):\n",
    "    def __init__(self, CSVfolder, process='train', transform = transforms.Compose([transforms.Resize(size=(224, 224)),transforms.ToTensor()]), imgFolder='../input/train/images/',labelsDict = {}, y_labels = list(train_data.category)):\n",
    "        \n",
    "        self.process = process\n",
    "        self.imgFolder = imgFolder\n",
    "        self.CSVfolder = CSVfolder\n",
    "        self.y = y_labels\n",
    "        self.FileList = pd.read_csv(self.CSVfolder)['image'].tolist()\n",
    "        self.transform = transform\n",
    "        self.labelsDict = labelsDict\n",
    "        \n",
    "        if self.process =='train':\n",
    "            self.labels = [labelsDict[i] for i in self.FileList]\n",
    "        else:\n",
    "            self.labels = [0 for i in range(len(self.FileList))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.FileList)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        file_name =  self.FileList[idx]\n",
    "        image_data=self.pil_loader(self.imgFolder+\"/\"+file_name)\n",
    "        \n",
    "        if self.transform:\n",
    "            image_data = self.transform(image_data)\n",
    "        \n",
    "        if self.process == 'train':\n",
    "            label = self.y[idx]\n",
    "        else:\n",
    "            label = file_name\n",
    "            \n",
    "        return image_data, label\n",
    "    \n",
    "    def pil_loader(self,path):\n",
    "        with open(path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJ_V7dI0EMOb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define the batchsize\n",
    "training_batchsize = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aUSsU8ADo3Z0"
   },
   "outputs": [],
   "source": [
    "#retrieve the full data\n",
    "full_data = ShipDataLoader(base_dir+'/train/train.csv',process = \"train\", imgFolder = base_dir+\"/train/images\", labelsDict = map_img_class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ApjY29eSo3S5"
   },
   "outputs": [],
   "source": [
    "#create a dataloader\n",
    "trainfull_loader = torch.utils.data.DataLoader(full_data, batch_size=training_batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "donjs5Z5Qrty"
   },
   "source": [
    "# Visualization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbXGfWDrQ0US"
   },
   "outputs": [],
   "source": [
    "# dictionary ship encoding \n",
    "ship = {1: 'Cargo', \n",
    "        2: 'Military', \n",
    "        3: 'Carrier', \n",
    "        4: 'Cruise', \n",
    "        5: 'Tankers'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Bt0vO-EQaw9"
   },
   "outputs": [],
   "source": [
    "#custom function to display images\n",
    "\n",
    "def imshow(img, title):\n",
    "    \n",
    "    #convert image from tensor to numpy for visualization\n",
    "    npimg = img.numpy()\n",
    "    #define the size of a figure\n",
    "    plt.figure(figsize = (15, 15))\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    #interchaging the image sizes - transposing\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title(title, fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LoNCtOwsQeF4"
   },
   "outputs": [],
   "source": [
    "#function to get images and feed into our custom function 'imshow'\n",
    "\n",
    "def show_batch_images(dataloader):\n",
    "    \n",
    "    #getting the images\n",
    "    images, labels = next(iter(dataloader))\n",
    "    #make a grid from those images\n",
    "    img = torchvision.utils.make_grid(images)\n",
    "    imshow(img, \"classes: \" + str([str(x.item())+ \" \"+ ship[x.item()] for x in labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "colab_type": "code",
    "id": "_W_KtnPrQfRS",
    "outputId": "753ed3c2-74ef-42ef-eb73-0525cea9e811"
   },
   "outputs": [],
   "source": [
    "show_batch_images(trainfull_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "colab_type": "code",
    "id": "h2UqQQ17QlUq",
    "outputId": "3d845bc2-ab8d-4bca-e7b9-60a8f6ae19ae"
   },
   "outputs": [],
   "source": [
    "show_batch_images(trainfull_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4itrRdqCvAxi"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "skyUwQhlQobt",
    "outputId": "4fcdda56-8515-4152-c17d-2a769680e96a"
   },
   "outputs": [],
   "source": [
    "#checking for available gpu\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "\n",
    "#define the number of classes for the final layer\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s6J36wPYvH-I"
   },
   "source": [
    "### Data Augmentation\n",
    "\n",
    "A common strategy for training neural networks is to introduce randomness in the input data itself. For example, you can randomly rotate, mirror, scale, and/or crop your images during training. This will help your network generalize as it's seeing the same images but in different locations, with different sizes, in different orientations, etc.\n",
    "\n",
    "To randomly rotate, scale and crop, then flip your images you would define your transforms like this:\n",
    "\n",
    "```python\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.5, 0.5, 0.5], \n",
    "```\n",
    "\n",
    "You'll also typically want to normalize images with `transforms.Normalize`. You pass in a list of means and list of standard deviations, then the color channels are normalized like so\n",
    "\n",
    "```input[channel] = (input[channel] - mean[channel]) / std[channel]```\n",
    "\n",
    "Subtracting `mean` centers the data around zero and dividing by `std` squishes the values to be between -1 and 1. Normalizing helps keep the network work weights near zero which in turn makes backpropagation more stable. Without normalization, networks will tend to fail to learn.\n",
    "\n",
    "You can find a list of all [the available transforms here](http://pytorch.org/docs/0.3.0/torchvision/transforms.html). When you're testing however, you'll want to use images that aren't altered (except you'll need to normalize the same way). So, for validation/test images, you'll typically just resize and crop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i0_r3ervvDZF"
   },
   "outputs": [],
   "source": [
    "Training_transforms = transforms.Compose([\n",
    "\ttransforms.Resize((224,224)),\n",
    "\ttransforms.RandomHorizontalFlip(),\n",
    "\ttransforms.ColorJitter(brightness=0.1,contrast=0.1,saturation=0.1, hue=0.1),\n",
    "\ttransforms.RandomAffine(degrees=15, translate=(0.3,0.3), scale=(0.5,1.5), shear=None, resample=False, fillcolor=0),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDU0n8huvyOk"
   },
   "outputs": [],
   "source": [
    "validation_transforms = transforms.Compose([\n",
    "\ttransforms.Resize((224,224)),\n",
    "\ttransforms.RandomHorizontalFlip(),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "\t\t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbUqPoflwDb5"
   },
   "outputs": [],
   "source": [
    "#### 90-10 train-validation split\n",
    "tr, val = train_test_split(train_data.category, stratify=train_data.category, test_size=0.15, random_state=10)\n",
    "\n",
    "### Batchsize and parallelize\n",
    "\n",
    "training_batchsize = 16\n",
    "num_workers = 8\n",
    "\n",
    "#### Idx for train and valid\n",
    "train_sampler = SubsetRandomSampler(list(tr.index)) \n",
    "valid_sampler = SubsetRandomSampler(list(val.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-IyyRvpO0NcE",
    "outputId": "b57dff01-146c-4946-9168-11d82f86e37e"
   },
   "outputs": [],
   "source": [
    "len(list(tr.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u2IdV40X0Plf",
    "outputId": "838332eb-5cd6-42ac-e792-603624e0c42c"
   },
   "outputs": [],
   "source": [
    "len(list(val.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxS3pW-Cw0QF"
   },
   "outputs": [],
   "source": [
    "#### Train dataloader ####\n",
    "traindataset = ShipDataLoader('../input/train/train.csv',\"train\", Training_transforms, '../input/train/images', map_img_class_dict)\n",
    "train_loader = torch.utils.data.DataLoader(traindataset, batch_size= training_batchsize ,sampler=train_sampler,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "yy3XJcayxIsH",
    "outputId": "7c145810-312f-444c-c0f7-669255235e03"
   },
   "outputs": [],
   "source": [
    "show_batch_images(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L-m37ZC9xdVo"
   },
   "outputs": [],
   "source": [
    "#### Valid dataloader ####\n",
    "\n",
    "valdataset = ShipDataLoader('../input/train/train.csv',\"train\", validation_transforms, '../input/train/images', map_img_class_dict)\n",
    "val_loader = torch.utils.data.DataLoader(valdataset, batch_size=training_batchsize,sampler=valid_sampler,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jaMqKIqfwKJN"
   },
   "outputs": [],
   "source": [
    "#### Test dataloader ####\n",
    "\n",
    "testdataset = ShipDataLoader('../input/train/train.csv',\"test\", validation_transforms, '../input/train/images', map_img_class_dict)\n",
    "test_loader = torch.utils.data.DataLoader(testdataset, batch_size=training_batchsize,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MyfgVj85x7sB"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "dajyQVj0yDhR",
    "outputId": "6e5a8331-9472-48b4-a04f-238ab7f9621d"
   },
   "outputs": [],
   "source": [
    "#create a iterator\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "#shape of images bunch\n",
    "print(images.shape)\n",
    "\n",
    "#shape of first image in a group of 4\n",
    "print(images[1].shape)\n",
    "\n",
    "#class label for first image\n",
    "print(labels[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LzOPCDfsyrRs",
    "outputId": "67b48b2c-b7da-4746-968b-80de8b97629c"
   },
   "outputs": [],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qRMJX7ugz5CO"
   },
   "outputs": [],
   "source": [
    "dataloaders = {\"train\": train_loader, \"val\": val_loader} \n",
    "dataset_sizes = {\"train\": len(list(tr.index)), \"val\": len(list(val.index))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2krQhgOy7_s"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    train_losses, test_losses = [], []\n",
    "    train_acc, test_acc = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device) - 1\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            if phase == \"train\":\n",
    "                train_losses.append(epoch_loss)\n",
    "                train_acc.append(epoch_acc)\n",
    "            elif phase == \"val\":\n",
    "                test_losses.append(epoch_loss)\n",
    "                test_acc.append(epoch_acc)\n",
    "                \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    \n",
    "    del inputs, labels\n",
    "    torch.cuda.empty_cache()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    #saving the best model\n",
    "    torch.save(model.state_dict(best_model_wts),\"saved.pth\")\n",
    "    print(\"best model saved\")\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_losses, test_losses, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(dataloader, trained_model):\n",
    "\n",
    "    pred = dict()\n",
    "    trained_model.eval()\n",
    "\n",
    "    for  data in dataloader:\n",
    "        images, labels = data\n",
    "        images = images.cuda()\n",
    "        \n",
    "        #push model to cuda\n",
    "        trained_model.cuda()\n",
    "        outputs = trained_model(images)\n",
    "        \n",
    "        #print(outputs)\n",
    "        for i in range(len(images)):\n",
    "            #print(torch.argmax(outputs[i]))\n",
    "            detect_class = torch.argmax(outputs[i]).item() + 1\n",
    "            pred[labels[i]] = detect_class   \n",
    "\n",
    "    df = pd.DataFrame(list(pred.items()), columns=['image', 'category'])\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "au_yQ061zszV"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zDlNBmsgyA1h"
   },
   "source": [
    "# Resnet 50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5807
    },
    "colab_type": "code",
    "id": "GlUCKTimyGz0",
    "outputId": "167d0da1-67ef-4222-d337-3d96b43bd0a3"
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet50(pretrained = True)\n",
    "\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DIefSsYMyV32",
    "outputId": "e32bbfe9-f102-4672-c0fd-7f56ce5f9f05"
   },
   "outputs": [],
   "source": [
    "#number of trainable parameters in resent101 - before freezing\n",
    "\n",
    "print(\"Number of trainable parameters: \", sum(p.numel() for p in model_ft.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "pJrv3FtGyn8q",
    "outputId": "4edf67c3-535c-46f1-da54-84513553c81c"
   },
   "outputs": [],
   "source": [
    "### Let's print the names of the layer stacks for our model\n",
    "for name, child in model_ft.named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qo5qh-u0ywp0"
   },
   "outputs": [],
   "source": [
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "fc = nn.Sequential(nn.Linear(model_ft.fc.in_features, 720),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(720, 256),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.4),\n",
    "                                nn.Linear(256, 64),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.3),\n",
    "                                nn.Linear(64, 5),\n",
    "                                nn.Softmax(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AgmW7NFmyyNx"
   },
   "outputs": [],
   "source": [
    "model_ft.fc = fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5966
    },
    "colab_type": "code",
    "id": "NyIs39KFyztc",
    "outputId": "bc26a841-6a7b-47f4-b4ba-f07e6ec5af7a"
   },
   "outputs": [],
   "source": [
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "D6oF9xt0zvVO",
    "outputId": "dfacd3db-4879-46e1-e32a-54ab4bfdaeed"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model_ft.parameters()), lr=0.0001, weight_decay=1e-3)\n",
    "\n",
    "# Decay LR by a factor of 0.15 every 7 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.15)\n",
    "\n",
    "scheduler_cosineAL = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_ft, len(train_loader), eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Resnet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1054
    },
    "colab_type": "code",
    "id": "EPAK9HlIz8vt",
    "outputId": "5078e016-5cb3-4622-b97b-dbffc1cdf359"
   },
   "outputs": [],
   "source": [
    "model_trained, train_lr, test_lr,train_acc, test_acc = train_model(model_ft, criterion, optimizer_ft, scheduler_cosineAL, num_epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1fVkfgN0pnz"
   },
   "outputs": [],
   "source": [
    "#plot the losses\n",
    "\n",
    "plt.plot(train_lr, label='Training loss')\n",
    "plt.plot(test_lr, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc, label = \"Training acc\")\n",
    "plt.plot(test_acc, label = \"Validation acc\")\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions - Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_res50 = make_predictions(test_loader, model_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_res50.rename(columns = {'category':'rs50_category'}, inplace = True) \n",
    "test_df_res50.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_res50.rs50_category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zDlNBmsgyA1h"
   },
   "source": [
    "# Resnet 101 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5807
    },
    "colab_type": "code",
    "id": "GlUCKTimyGz0",
    "outputId": "167d0da1-67ef-4222-d337-3d96b43bd0a3"
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet101(pretrained = True)\n",
    "\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DIefSsYMyV32",
    "outputId": "e32bbfe9-f102-4672-c0fd-7f56ce5f9f05"
   },
   "outputs": [],
   "source": [
    "#number of trainable parameters in resent101 - before freezing\n",
    "\n",
    "print(\"Number of trainable parameters: \", sum(p.numel() for p in model_ft.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "pJrv3FtGyn8q",
    "outputId": "4edf67c3-535c-46f1-da54-84513553c81c"
   },
   "outputs": [],
   "source": [
    "### Let's print the names of the layer stacks for our model\n",
    "for name, child in model_ft.named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qo5qh-u0ywp0"
   },
   "outputs": [],
   "source": [
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "fc = nn.Sequential(nn.Linear(model_ft.fc.in_features, 720),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(720, 256),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.4),\n",
    "                                nn.Linear(256, 64),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.3),\n",
    "                                nn.Linear(64, 5),\n",
    "                                nn.Softmax(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AgmW7NFmyyNx"
   },
   "outputs": [],
   "source": [
    "model_ft.fc = fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5966
    },
    "colab_type": "code",
    "id": "NyIs39KFyztc",
    "outputId": "bc26a841-6a7b-47f4-b4ba-f07e6ec5af7a"
   },
   "outputs": [],
   "source": [
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "D6oF9xt0zvVO",
    "outputId": "dfacd3db-4879-46e1-e32a-54ab4bfdaeed"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model_ft.parameters()), lr=0.0001, weight_decay=1e-3)\n",
    "\n",
    "scheduler_cosineAL = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_ft, len(train_loader), eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Resnet101 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1054
    },
    "colab_type": "code",
    "id": "EPAK9HlIz8vt",
    "outputId": "5078e016-5cb3-4622-b97b-dbffc1cdf359"
   },
   "outputs": [],
   "source": [
    "model_trained, train_lr, test_lr,train_acc, test_acc = train_model(model_ft, criterion, optimizer_ft, scheduler_cosineAL, num_epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1fVkfgN0pnz"
   },
   "outputs": [],
   "source": [
    "#plot the losses\n",
    "\n",
    "plt.plot(train_lr, label='Training loss')\n",
    "plt.plot(test_lr, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc, label = \"Training acc\")\n",
    "plt.plot(test_acc, label = \"Validation acc\")\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions - Resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_res101 = make_predictions(test_loader, model_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_res101.rename(columns = {'category':'rs101_category'}, inplace = True) \n",
    "\n",
    "test_df_res101.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_res101.rs101_category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zDlNBmsgyA1h"
   },
   "source": [
    "# resnet152 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5807
    },
    "colab_type": "code",
    "id": "GlUCKTimyGz0",
    "outputId": "167d0da1-67ef-4222-d337-3d96b43bd0a3"
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet152(pretrained = True)\n",
    "\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DIefSsYMyV32",
    "outputId": "e32bbfe9-f102-4672-c0fd-7f56ce5f9f05"
   },
   "outputs": [],
   "source": [
    "#number of trainable parameters in resent101 - before freezing\n",
    "\n",
    "print(\"Number of trainable parameters: \", sum(p.numel() for p in model_ft.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "pJrv3FtGyn8q",
    "outputId": "4edf67c3-535c-46f1-da54-84513553c81c"
   },
   "outputs": [],
   "source": [
    "### Let's print the names of the layer stacks for our model\n",
    "for name, child in model_ft.named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qo5qh-u0ywp0"
   },
   "outputs": [],
   "source": [
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "fc = nn.Sequential(nn.Linear(model_ft.fc.in_features, 720),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(720, 256),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.4),\n",
    "                                nn.Linear(256, 64),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.3),\n",
    "                                nn.Linear(64, 5),\n",
    "                                nn.Softmax(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AgmW7NFmyyNx"
   },
   "outputs": [],
   "source": [
    "model_ft.fc = fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5966
    },
    "colab_type": "code",
    "id": "NyIs39KFyztc",
    "outputId": "bc26a841-6a7b-47f4-b4ba-f07e6ec5af7a"
   },
   "outputs": [],
   "source": [
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "D6oF9xt0zvVO",
    "outputId": "dfacd3db-4879-46e1-e32a-54ab4bfdaeed"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model_ft.parameters()), lr=0.0001, weight_decay=1e-3)\n",
    "\n",
    "scheduler_cosineAL = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_ft, len(train_loader), eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Training resnet152 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1054
    },
    "colab_type": "code",
    "id": "EPAK9HlIz8vt",
    "outputId": "5078e016-5cb3-4622-b97b-dbffc1cdf359"
   },
   "outputs": [],
   "source": [
    "model_trained, train_lr, test_lr,train_acc, test_acc = train_model(model_ft, criterion, optimizer_ft, scheduler_cosineAL, num_epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1fVkfgN0pnz"
   },
   "outputs": [],
   "source": [
    "#plot the losses\n",
    "\n",
    "plt.plot(train_lr, label='Training loss')\n",
    "plt.plot(test_lr, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc, label = \"Training acc\")\n",
    "plt.plot(test_acc, label = \"Validation acc\")\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions - resnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_res152 = make_predictions(test_loader, model_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_res152.rename(columns = {'category':'res152_category'}, inplace = True) \n",
    "\n",
    "test_df_res152.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_res152.res152_category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results = [df.set_index(['image']) for df in [test_df_res50, test_df_res101, test_df_res152]]\n",
    "merge_results = pd.concat(merge_results_lst, axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_pred = merge_results.drop(\"image\", axis = 1)\n",
    "merged_pred = merged_pred.mode(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame({\"image\": list(merge_results.image)})\n",
    "final_df[\"category\"] = merged_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"final_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GameDeepLearning_ShipClassification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
